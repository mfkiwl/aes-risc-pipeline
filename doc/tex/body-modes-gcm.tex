% =============================================================================

\begin{adjustbox}{center,caption={Instruction    counts for multiplication in $\F_{2^{128}}$ as used by \ALG{GHASH}.
                                 },label={tab:gcm:instrs},float={table}[!ht]}
\centering
\begin{tabular}{|c|c|c|rrrrrr|}
\hline
ISA    & Karatsuba & Reduce & \VERB{grev}
                            & \VERB{xor}
                            & \VERB{s[lr]li}
                            & \VERB{clmul} 
                            & \VERB{clmulh}
                            & Total \\
\hline
\hline
RV32IB &        no &    mul &$  4$&$ 36$&$  0$&$ 20$&$ 20$&$ 80$ \\
RV32IB &        no &  shift &$  4$&$ 56$&$ 24$&$ 16$&$ 16$&$116$ \\
RV32IB &       yes &    mul &$  4$&$ 52$&$  0$&$ 13$&$ 13$&$ 82$ \\
RV32IB &       yes &  shift &$  4$&$ 72$&$ 24$&$  9$&$  9$&$118$ \\
\hline
RV64IB &        no &    mul &$  2$&$ 10$&$  0$&$  6$&$  6$&$ 24$ \\
RV64IB &        no &  shift &$  2$&$ 20$&$ 12$&$  4$&$  4$&$ 42$ \\
RV64IB &       yes &    mul &$  2$&$ 14$&$  0$&$  5$&$  5$&$ 26$ \\
RV64IB &       yes &  shift &$  2$&$ 24$&$ 12$&$  3$&$  3$&$ 44$ \\
\hline
\end{tabular}
\end{adjustbox}

\begin{adjustbox}{center,caption={Modelled cycle counts for multiplication in $\F_{2^{128}}$ as used by \ALG{GHASH}.
                                 },label={tab:gcm:cycles},float={table}[!ht]}
\centering
\begin{tabular}{|c|c|c|rrrr|}
\hline
ISA    & Karatsuba & Reduce & $1$-cycle       & $2$-cycle       & $3$-cycle       & $6$-cycle       \\
       &           &        & \VERB{clmul[h]} & \VERB{clmul[h]} & \VERB{clmul[h]} & \VERB{clmul[h]} \\
\hline
\hline
RV32IB &        no &    mul &     \bftab  80  &            120  &            160  &            280  \\
RV32IB &        no &  shift &            116  &            148  &            180  &            276  \\
RV32IB &       yes &    mul &             82  &    \bftab  108  &     \bftab 134  &            212  \\
RV32IB &       yes &  shift &            118  &            136  &            154  &     \bftab 208  \\
\hline
RV64IB &        no &    mul &     \bftab  24  &    \bftab   36  &             48  &             84  \\
RV64IB &        no &  shift &             42  &             50  &             58  &             82  \\
RV64IB &       yes &    mul &             26  &    \bftab   36  &     \bftab  46  &             76  \\
RV64IB &       yes &  shift &             44  &             50  &             56  &     \bftab  74  \\
\hline
\end{tabular}
\end{adjustbox}

\begin{adjustbox}{center,caption={
    Hardware implementation metrics for each ISE variant with
    only encrypt instructions implemented.
                                 },label={tab:eval:hw:dec},float={table}[!ht]}
\centering
\begin{tabular}{|c|l|rr|r|r|}
\hline
  \multicolumn{1}{|c|}{ISA}
& \multicolumn{1}{ c|}{Variant}
& \multicolumn{1}{ c|}{             ISE}
& \multicolumn{1}{ c|}{       ISE Path }
& \multicolumn{1}{ c|}{\CORE{2}     CPU}
& \multicolumn{1}{ c|}{\CORE{1}     CPU}
\\
& \multicolumn{1}{ c|}{/ Goal       }
& \multicolumn{1}{ c|}{Area         }
& \multicolumn{1}{ c|}{Depth        }
& \multicolumn{1}{ c|}{$+$ ISE area }
& \multicolumn{1}{ c|}{$+$ ISE area }
\\
\hline
\hline
 RV32IMC & Baseline    &              &            &       37325  ($1.00\times$) &       3501576 ($1.000\times$) \\
 RV32IMC & \ISE{1} (L) &        1605  & \bftab 17  &       39154  ($1.05\times$) &       3506224 ($1.001\times$) \\
 RV32IMC & \ISE{1} (A) &        1038  &        23  &       38561  ($1.05\times$) &       3505695 ($1.001\times$) \\
 RV32IMC & \ISE{2} (L) &        1611  & \bftab 17  &       40337  ($1.03\times$) &       3506729 ($1.001\times$) \\
 RV32IMC & \ISE{2} (A) &         780  &        21  &       38479  ($1.08\times$) &       3505910 ($1.001\times$) \\
 RV32IMC & \ISE{3}     & \bftab  630  &        25  &\bftab 38301  ($1.03\times$) &       3506097 ($1.001\times$) \\
 RV32IMC & \ISE{5} (L) &        1852  &        23  &       40626  ($1.03\times$) &       3507518 ($1.001\times$) \\
 RV32IMC & \ISE{5} (A) &        1048  &        23  &       38749  ($1.09\times$) &       3506816 ($1.001\times$) \\
\hline
\hline
 RV64IMC & Baseline &          &          &  N/A  & 3717607 (1.000$\times$) \\
 RV64IMC & \ISE{4}  &  3790    &    27    &  N/A  & 3728235 (1.003$\times$) \\
\hline
\end{tabular}
\end{adjustbox}


% -----------------------------------------------------------------------------

\noindent
The Galois/Counter Mode (GCM) ~\cite{NIST:sp.800.38d}
is a block cipher mode of operation which 
supports authenticated encryption.
AES-GCM refers to an instantiation using AES as the underlying block cipher, 
which is the only case mandated by TLS 1.3~\cite[Section 9.1]{rfc:8446}; the
importance of this construction means GCM and AES are frequently considered 
together from an implementation and evaluation perspective.
The computational core of AES-GCM is formed from two components.
\ALG{GCTR} ~\cite[Section 6.5]{NIST:sp.800.38d}
is responsible for 
    encryption
using AES,
and
\ALG{GHASH}~\cite[Section 6.4]{NIST:sp.800.38d}
is responsible for
authentication.
Having dealt with efficient implementation of AES and hence \ALG{GCTR} in
\REFSEC{sec:ise}, we turn our attention to \ALG{GHASH}.  
Rather than further 
embellish the ISE for AES, we instead focus on re-use of the proposed
standard 
Bit-manipulation ~\cite[Section 17]{RV:ISA:I:19}
(At the time of writing, the draft extension proposal is found in
\cite{riscv:bitmanip:draft})
extension.
This approach is attractive for two reasons.
AES-GCM is a very common construction, but AES is not the only block
cipher which can be used with GCM.
Likewise, AES may not always be used with GCM, so separation of
the two constructs from an instruction set point of view is prudent.

% -----------------------------------------------------------------------------

\paragraph{Implementation.}

\ALG{GHASH}~\cite[Section 6.4]{NIST:sp.800.38d} is a universal hash defined 
over the finite field $\F_{2^{128}}$ constructed as
$
\F_{2}[\IND{x}] / ( \IND{x}^{128} + \IND{x}^{7} + \IND{x}^{2} + \IND{x} + 1 ) .
$
Conversion of the input into the correct endianness can be realised using
the 
\VERB{grev} (or generalised reverse)
instruction,
which can reverse the bits in each byte of an input word:
$4$ (resp. $2$) 
\VERB{grev} 
instructions are therefore required on RV32IB (resp. RV64IB).
Beyond this, operations in $\F_{2^{128}}$ dominate.
Addition       in $\F_{2^{128}}$ 
is equivalent to XOR: thus
$4$ (resp. $2$) 
\VERB{xor} 
instructions are required on RV32IB (resp. RV64IB).
Multiplication in $\F_{2^{128}}$ 
can be split into two steps:
a $( 128 \times 128 )$-bit polynomial multiplication, 
followed by 
a reduction of the $256$-bit result modulo
$
\IND{x}^{128} + \IND{x}^{7} + \IND{x}^{2} + \IND{x} + 1 .
$

The multiplication step 
can be realised using pairs of ``carry-less'' multiplication instructions
\VERB{clmul} and \VERB{clmulh}.
These compute the least significant (resp. most-significant) 
half of a carry-less product (i.e., product over $\F_2$).
Pairs of 
\VERB{clmul} and \VERB{clmulh}
should be scheduled adjacently, allowing capable micro-architectures
to fuse them.
Use of a school book approach 
requires
$16$ (resp. $4$) pairs 
on RV32IB (resp. RV64IB).
Optimisation using the Karatsuba method
requires
$ 9$ (resp. $3$) such pairs 
on RV32IB (resp. RV64IB),
plus some additional \VERB{xor} instructions.

The reduction step
can be implemented in two ways:
a shift-based reduction, made possible by the low Hamming weight of the
primitive polynomial,
or
a multiplication-based reduction, analogous to the Montgomery or Barret
methods.
The most efficient approach depends on the relative execution 
latency of
\VERB{clmul[h]}
vs.
\VERB{xor} and \VERB{s[lr]li}.
Note that the entire \ALG{GHASH} operation, including \VERB{clmul[h]},
{\em must} exhibit data-oblivious execution latency 
(e.g., avoid data-dependent optimisations like early-termination)
to avoid associated side-channel attacks (cf.~\cite{GOPT:09}).

% -----------------------------------------------------------------------------

\paragraph{Discussion.}

\REFTAB{tab:gcm:instrs} 
lists instruction counts for 
multiplication in $\F_{2^{128}}$,
implemented using combinations of the base ISA, and approaches
for the polynomial multiplication and reduction steps.
\REFTAB{tab:gcm:cycles} 
then models the execution latency 
(measured in cycles)
assuming \VERB{grev}, \VERB{xor}, and \VERB{s[lr]li} take $1$ cycle.
Although the model only considers an in-order core in line with those used
in \REFSEC{sec:ise} and is focused on execution latency
(vs. other pertinent metrics, such as code footprint),
there are two obvious conclusions:
if
\VERB{clmul[h]}
has $2$ (or more) times the latency of
\VERB{xor} and \VERB{s[lr]li},
a 
Karatsuba
polynomial multiplication
is preferable.
If
\VERB{clmul[h]}
has $6$ (or more) times the latency of
\VERB{xor} and \VERB{s[lr]li},
a shift-based 
reduction 
is preferable.

We recommend the carry-less multiply instructions
specified in the proposed RISC-V Bit-manipulation extension also be included
in the RISC-V cryptography extension.
Implementers would otherwise need to implement (a subset of) the B
extension, potentially adding functionality and cost that is not
nessesary.

An important consideration for the GCTR component of GCM is that it only
requires the encryption function for a block cipher.
Given this, we re-evaluate the hardware costs of each ISE, assuming that
only the encryption instructions are implemented.
These results are shown in \REFTAB{tab:eval:hw:dec}.
Unsupprisingly, the area overhead is approximately halved, and there is
a small reduction in circuit depth.
For very constrained devices which have exact functionality
requirements, we believe that making implementation of the decryption
instruction optional could be benefical.
If these systems {\em do} require AES decryption, it could still be
implemented in software, with a performance and code size similar
to the baseline implementations in
\REFTAB{tab:eval:sw:perf:2}
and
\REFTAB{tab:eval:sw:perf:1}.

% =============================================================================
